{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding column names & converting the file to csv format\n",
    "df = pd.read_csv(\"D:\\\\Cipher\\\\adult.data.txt\",delimiter=',', names = [\"Age\" , \"Workclass\" , \"ID\" , \"Education\" ,\n",
    "                                                                      \"Education_num\" , \"Marital_Status\", \n",
    "                                                                      \"Occupation\" , \"Relationship\" , \"Race\" , \n",
    "                                                                      \"Sex\" , \"Capital_Gain\" , \"Capital_Loss\" ,\n",
    "                                                                      \"Hrs_per_week\" , \"Country\" , \"Target\" ])\n",
    "df.to_csv('adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data pre-processing\n",
    "df.isin(['?']).sum(axis=0)   \n",
    "df = df.replace(to_replace = ' ?', value = np.nan)\n",
    "\n",
    "#Checking for the number of missing values in each column\n",
    "df.isnull().sum()  \n",
    "\n",
    "#dropping all the nan rows\n",
    "df.dropna(how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the ratio of output variables\n",
    "print(df['Target'].value_counts(sort=False)[1] / (df['Target'].value_counts(sort=False)[1] + df['Target'].value_counts(sort=False)[0]))\n",
    "print(df['Target'].value_counts(sort=False)[0] / (df['Target'].value_counts(sort=False)[1] + df['Target'].value_counts(sort=False)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding the target variable, Since there are binary outputs    \n",
    "label_encod = LabelEncoder()\n",
    "df['Target'] = label_encod.fit_transform(df['Target'])\n",
    "\n",
    "#Encoding the gender variable\n",
    "label_encod = LabelEncoder()\n",
    "df['Sex'] = label_encod.fit_transform(df['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection\n",
    "for column in df:\n",
    "    print(df[column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a bar graph to check and filter redundant variables from the dataset\n",
    "df.groupby('Age').Target.mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Workclass').Target.mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Education').Target.mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Education_num').Target.mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Race').Target.mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping all the redundant columns containing noisy data\n",
    "df = df.drop(['ID', 'Occupation', 'Country' , 'Capital_Loss' , 'Capital_Gain' , 'Hrs_per_week' , 'Age'] , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting categorical data to numerical data\n",
    "\n",
    "df['Workclass'] = df['Workclass'].map({' Self-emp-inc': 0, ' State-gov': 1,' Federal-gov': 2, ' Without-pay': 3, ' Local-gov': 4,' Private': 5, ' Self-emp-not-inc': 6}).astype(int)\n",
    "\n",
    "df['Race'] = df['Race'].map({' Black': 0, ' Asian-Pac-Islander': 1,' Other': 2, ' White': 3, ' Amer-Indian-Eskimo': 4}).astype(int)\n",
    "\n",
    "df['Education'] = df['Education'].map({' Some-college': 0 , ' Preschool': 1 , ' 5th-6th': 2 , ' HS-grad': 3 , ' Masters': 4 , ' 12th': 5 , ' 7th-8th': 6, ' Prof-school': 7 ,' 1st-4th': 8, ' Assoc-acdm': 9, ' Doctorate': 10, ' 11th': 11 ,' Bachelors': 12, ' 10th': 13,' Assoc-voc': 14 ,' 9th': 15}).astype(int)\n",
    "\n",
    "df['Relationship'] = df['Relationship'].map({' Not-in-family': 0 , ' Wife': 1 , ' Other-relative': 2, ' Unmarried': 3 ,' Husband': 4 ,' Own-child': 5}).astype(int)\n",
    "\n",
    "df['Marital_Status'] = df['Marital_Status'].map({' Married-spouse-absent': 0 , ' Widowed': 1 , ' Married-civ-spouse': 2 , ' Separated': 3 , ' Divorced': 4 ,' Never-married': 5 , ' Married-AF-spouse': 6}).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Target' , axis = 1)\n",
    "Y = df['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the K best features from the dataset\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=5)\n",
    "fit = bestfeatures.fit(X,Y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "scores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "scores.columns = ['specs','score']\n",
    "print(scores.nlargest(5,'score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Logistic Regression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"              Logistic Regression                \")\n",
    "CM = confusion_matrix(y_test, y_pred)\n",
    "CR = classification_report(y_test, y_pred)\n",
    "AC = accuracy_score(y_test, y_pred)\n",
    "print()\n",
    "print(\"Confusion matrix:\\n\" , CM )\n",
    "print()\n",
    "sns.heatmap(CM, annot = True)\n",
    "print(\"Accuracy Score:\", (AC)*100)\n",
    "print(\"Classification Report:\\n\", CR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Naive Bayes\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Naive Bayes\")\n",
    "CM = confusion_matrix(y_test, y_pred)\n",
    "CR = classification_report(y_test, y_pred)\n",
    "AC = accuracy_score(y_test, y_pred)\n",
    "print()\n",
    "print(\"Confusion matrix:\\n\" , CM )\n",
    "print()\n",
    "sns.heatmap(CM, annot = True)\n",
    "print(\"Accuracy Score:\", (AC)*100)\n",
    "print(\"Classification Report:\\n\", CR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Random Forest Classifier & checking the optimal n_estimator which provides an accurate response\n",
    "error_rate = []\n",
    "for i in range(10,100,10):\n",
    "    RFC = RandomForestClassifier(n_estimators = i, random_state = 0 )\n",
    "    RFC.fit(X_train, y_train)\n",
    "    pred = RFC.predict(X_test)\n",
    "    error_rate.append(np.mean(pred != y_test))\n",
    "\n",
    "#Plotting the range vs error_rate graph which specifies at what value, the error is minimum\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.plot(range(10,100,10), error_rate, linestyle = 'dashed', color = 'blue', marker = 'o')\n",
    "plt.title(\"Range vs Error rate\")\n",
    "plt.xlabel(\"Range\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying KNN & checking the optimal number of neighbours which gives a minimum error rate\n",
    "error_rate = []\n",
    "for k in range(1,40):\n",
    "    knn = KNeighborsClassifier(n_neighbors = k, metric = 'minkowski', p = 2)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred != y_test))\n",
    "\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.plot(range(1,40), error_rate, linestyle = 'dashed', color = 'blue', marker = 'o')\n",
    "plt.title(\"Epochs vs Error_rate\")\n",
    "plt.xlabel(\"Error_rate\")\n",
    "plt.ylabel(\"Epochs\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
